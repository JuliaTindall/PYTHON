#!/usr/bin/env python2
# -*- coding: utf-8 -*-
"""
Created on 29.03.2022 by Julia

We will try and create some cloud regiemes from IPSL data 
"""
import numpy as np
import iris
#from iris.experimental.equalise_cubes import equalise_attributes
import iris.quickplot as qplt
import matplotlib.pyplot as plt

# stuff for kmeans clustering
#from kneed import KneeLocator
#from sklearn.datasets import make_blobs
#from sklearn.cluster import KMeans
#from sklearn.preprocessing import StandardScaler
#from sklearn.metrics import silhouette_score
#from sklearn.preprocessing import StandardScalar

import sys

  

def get_albedo_ctp(joint_pdf_cube,tcc_cube):
    """
    this will estimate the albedo from the jointpdf cube instead of the file
    """
    # albedos corresponding to the optical depths in the pdf boxes
    # from williams and webb 2008
    albedos = [0.028, 0.107, 0.232, 0.407, 0.626, 0.828, 0.950]
    ctp = joint_pdf_cube.coord('pressure2').points
    tau = joint_pdf_cube.coord('atmosphere_optical_thickness_due_to_cloud').points
    # when calculating albedo it is unclear whether we should average over all points in the histogram or only over those where there is cloud.  
    # I have decided to only average over those where there is cloud, because it is cloud albedo not total albedo
    nt, npress, ntau, ny,nx = joint_pdf_cube.shape # nt = times, npress=pressures, ntau =optical depth, ny = latitude, nx=lonagitude
    albedo_data = np.zeros((nt,ny,nx))
    ctp_data = np.zeros((nt,ny,nx))
    for t in range(0,nt): # over times
        print('t is',t)
        for j in range(0,ny): # over lats'
            for i in range(0,nx): # over lons'
                temporary = joint_pdf_cube[t,:,:,j,i]
                datapdf=temporary.data
                meanalbedo=0.0
                avgctp =0.0
                divisor=0.0
                for ictp in range(0,npress): # over ctp
                    for itau in range(0,ntau): # over optical depth
                        if datapdf[ictp,itau] > 0.0:
                            meanalbedo = (meanalbedo +
                                        (datapdf[ictp,itau] * albedos[itau]))
                            avgctp = (avgctp + datapdf[ictp,itau] *ctp[ictp])
                            divisor = divisor + datapdf[ictp,itau]
                if divisor > 0:
                    albedo_data[t,j,i] = meanalbedo / divisor
                    ctp_data[t,j,i] = avgctp /divisor
                else:
                    albedo_data[t,j,i]=0
                    ctp_data[t,j,i]=0
    albedo_cube = tcc_cube.copy(data=albedo_data)
    ctp_cube = tcc_cube.copy(data=ctp_data)
   
    albedo_cube.long_name = 'albedo'
    ctp_cube.long_name = 'ctp'
    return albedo_cube, ctp_cube

def get_pdfcubes_region(tstart,tend):
    """
    gets the pdfcube and extracts the points that are required only
    input:  cube is the joint histograms for the globe
    """

    # this dictionary has latmin, latmax, lonmin, lonmax
    latlons = {"TWP" : [-20.0, 20.0, 130., 200.0]}

    # read in the file
    cube = iris.load_cube(FILENAME)
    cube.coord('atmosphere_optical_thickness_due_to_cloud').bounds=None
    iris.util.promote_aux_coord_to_dim_coord(cube,'atmosphere_optical_thickness_due_to_cloud')
    cube.attributes = None
    cube.cell_methods = None
    
    # extract the data for the region
    reglatlons = latlons.get(REGION)
    region_constraint = iris.Constraint(
        latitude = lambda cell: reglatlons[0] <= cell <= reglatlons[1], 
        longitude = lambda cell2: reglatlons[2] <=cell2 <=reglatlons[3]
    ) 
    lats = cube.coord('latitude').points
    lons = cube.coord('longitude').points

    print('got region cube')
    region_pdf_cube_full = cube.extract(region_constraint)
    print(region_pdf_cube_full)
    region_pdf_cube = region_pdf_cube_full[tstart:tend, :,:,:,:]
    region_pdf_cube_full = 0
    cube =0.
    
    # get ctp, cloud tau, cloud albedo and cloud amount
    
    cloud_amount_cube = region_pdf_cube.collapsed(['pressure2','atmosphere_optical_thickness_due_to_cloud'],iris.analysis.SUM)
    cloud_amount_cube.long_name = 'tcc'
    print('got cloud amount cube')
    albedo_cube,ctp_cube = get_albedo_ctp(region_pdf_cube,cloud_amount_cube)

    fileout = '/nfs/hera1/earjcti/ISCCP/IPSL/'+REGIONNAMES.get(REGION)+'/tcc_alb_tcp_' + REGION + '_' + np.str(tstart) + '_' + np.str(tend) + '.nc'
    iris.save([region_pdf_cube,cloud_amount_cube, albedo_cube, ctp_cube],fileout,netcdf_format = "NETCDF3_CLASSIC",fill_value = -99999)
    sys.exit(0)

    
  
    for k in range(0, 200,10):
        pdf = jointpdf_cube.data[k,:,:]
        ax=plt.subplot(4,5,np.int(np.floor(k/10)+1))
        cs = ax.pcolormesh(pdf)
        if k==0 or k==50 or k==100 or k==150:
            plt.yticks([1,2,3,4,5,6,7], cloudtop_press/100., size=7)
        else:
            ax.set_yticklabels(dummy)
        if k>=150:
            plt.xticks([1,2,3,4,5,6,7], optical_depth, size=7,rotation=90)
        else:
            ax.set_xticklabels(dummy)
        plt.colorbar(cs)
        #plt.title(np.str(k) + ': ctp='+ "{:.2f}".format(mean_ctp_cube.data[k]),fontsize=7) 
        plt.title('alb='+"{:.2f}".format(mean_albedo_alt_cube.data[k]) + ': ctp='+ "{:.2f}".format(mean_ctp_alt_cube.data[k])+"\n" + 'tcc=' + "{:.2f}".format(mean_tcc_alt_cube.data[k]),fontsize=8)
    plt.savefig('tropics_sample20.eps')
    plt.close()

    return (jointpdf_cube.data,cloudtop_press, optical_depth,
            mean_ctp_alt_cube, mean_tcc_alt_cube, mean_albedo_alt_cube)
################################################################
def get_cloud_regiemes(joint_pdf_data, NK, cloud_regiemes, ctp, tau):
    """
    We are subsetting the joint_pdf_data into NK cloud regiemes
    We have some cloud_regiemes to start off with in cloud_regiemes
     
    For each pdf in joint_pdf_data
    1. decide which cloud regieme is nearest to this pdf
    2. add the pdf to this cloud regieme
    3. recalculate the cloud regieme with the addition of this pdf
    """
    fig = plt.figure(figsize=[11.4,11.4])
    dummy = [' ',' ',' ',' ',' ',' ',' ']
    nz, ny, nx = np.shape(joint_pdf_data)
    for k in range(0, 200,40):
        pdf = joint_pdf_data[:,:,k]
        ax=plt.subplot(4,5,k+1)
        cs = ax.pcolormesh(pdf)
        if k >=15:
            plt.xticks([1,2,3,4,5,6,7], tau, size=7, rotation=90)
        else:
            ax.set_xticklabels(dummy)
        if k==0 or k==5 or k==10 or k==15:
            plt.yticks([1,2,3,4,5,6,7], ctp, size=7)
        else:
            ax.set_yticklabels(dummy)
        plt.colorbar(cs)
        plt.title(np.str(k))
    plt.savefig('first20_histograms.eps')
    plt.close()


def test_sklearn(joint_pdf_data, tau, ctp):
    """
    testing stuff from the tutorial
    """
    nclusters=8
    nx, ny, nz = joint_pdf_data.shape
    joint_pdf_reshape = joint_pdf_data[:, :, :].reshape((nx * ny, nz))
    joint_pdf = np.transpose(joint_pdf_reshape)
    print(joint_pdf_reshape.shape)
    plt.subplot(2,1,1)
    for i in range(0,20):
        plt.plot(joint_pdf_reshape[:,i])

    kmeans = KMeans(init="random", n_clusters=nclusters, n_init=10)
    which_cluster=kmeans.fit_predict(joint_pdf)
    print(which_cluster[0:20])

    print(kmeans.cluster_centers_.shape)
    cluster_centers = kmeans.cluster_centers_.reshape((nclusters,nx, ny))
    plt.subplot(2,1,2)
    for i in range(0,nclusters):
        plt.plot(kmeans.cluster_centers_[i,:])
    plt.savefig('2d_clusters.eps')
    plt.close()
  
    fig = plt.figure(figsize=[11.4,11.4])
    print('cluster centers shape', cluster_centers.shape)

    for i in range(0,nclusters):
        ax = plt.subplot(3,3,i+1)
        cs = ax.pcolormesh(cluster_centers[i, :, :])
        plt.xticks([1,2,3,4,5,6,7], tau, size=7, rotation=90)
        plt.yticks([1,2,3,4,5,6,7], ctp, size=7)
        plt.colorbar(cs)
    plt.savefig('test_clusters.eps')
    print('kmeans niter',kmeans.n_iter_)
    plt.close()
    # elbow method to see how many clusters
    #see=[]
    #for k in range(1,31):
    #    kmeans = KMeans(n_clusters=k)
    #    kmeans.fit(joint_pdf)
    #    see.append(kmeans.inertia_)
    #plt.plot(range(1,31),see)
    #plt.show()

       

def test_sklearn_tropics(joint_pdf_data, tau, ctp):
    """
    testing stuff from the tutorial
    """


    nclusters=9
    nx, ny, nz = joint_pdf_data.shape
    joint_pdf = joint_pdf_data[:, :, :].reshape((nx,nz * ny))
    print(joint_pdf.shape)
    
    scalar = StandardScaler()
    scale = scalar.fit_transform(joint_pdf)
    joint_pdf = scale
    print(joint_pdf_data)
    plt.subplot(2,1,1)
    for i in range(0,20):
        plt.plot(joint_pdf[i,:])

    kmeans = KMeans(init="k-means++", n_clusters=nclusters, n_init=10)
    which_cluster=kmeans.fit_predict(joint_pdf)
    print(which_cluster)
    total_in_cluster = np.zeros(nclusters)
    largest_cluster=0
    for i in range(0,nclusters):
        total_in_cluster[i] = np.sum((np.where(which_cluster == i, 1.0, 0.0)))
        if total_in_cluster[i] == np.max(total_in_cluster):
            largest_cluster=i

    print(kmeans.cluster_centers_.shape)
    cluster_centers = kmeans.cluster_centers_.reshape((nclusters,nz, ny))
    #plt.subplot(2,1,2)
    #for i in range(0,nclusters):
    #    plt.plot(kmeans.cluster_centers_[i,:])
    #plt.savefig('2d_clusters.eps')
    #plt.close()
  
    fig = plt.figure(figsize=[11.4,11.4])
    print('cluster centers shape', cluster_centers.shape)

    for i in range(0,nclusters):
        ax = plt.subplot(3,3,i+1)
        cs = ax.pcolormesh(cluster_centers[i, :, :])
        plt.xticks([1,2,3,4,5,6,7], tau, size=7, rotation=90)
        plt.yticks([1,2,3,4,5,6,7], ctp, size=7)
        plt.title("{:.1f}".format(total_in_cluster[i] *100./ np.sum(total_in_cluster)) + '%')
        plt.colorbar(cs)
    plt.savefig('test_clusters.eps')
    print('kmeans niter',kmeans.n_iter_)
    print('largest cluster',largest_cluster)
    plt.close()
    # elbow method to see how many clusters
    #see=[]
    #for k in range(1,31):
    #    kmeans = KMeans(n_clusters=k)
    #    kmeans.fit(joint_pdf)
    #    see.append(kmeans.inertia_)
    #plt.plot(range(1,31),see)
    #plt.show()

 ##########################################################
def tropical_cloud_regiemes(CTP_data, TCC_data, albedo_data,
                            joint_pdf_data, ctpall, tauall):
    """
    estimates the cloud regieme for each tropical gridpoint
    """
    REGIEME_NAMES_TR = {0:"Shallow cumulus", 1:"Congestus",
                 2:"Thin cirrus", 3:"Stratocu./Cu. Transition",
                 4:"Anvil cirrus", 5:"Deep Convection",
                        6:"Stratocumulus", 7:"ClearSky"}
    REG_CHARS = {0:[0.261, 0.652, 0.314], 
                 1:[0.339, 0.483, 0.813],
                 2:[0.211, 0.356, 0.740],
                 3:[0.338, 0.784, 0.640],
                 4:[0.313, 0.327,0.944],
                 5:[0.532, 0.285,0.979],
                 6:[0.446, 0.722, 0.824]}

    regieme=np.zeros(len(CTP_data))
    min_dists=np.zeros(len(CTP_data))
    nz, ny, nx = np.shape(joint_pdf_data)
    regieme_pdf = np.zeros((8, ny, nx))
    regieme_count = np.zeros((8))
    dists = np.zeros(7)
    for i,ctp in enumerate(CTP_data):
        features = np.array([albedo_data[i], ctp, TCC_data[i]])
        if TCC_data[i] < 0.05:
            regieme[i]=7
            regieme_pdf[7,:,:] = joint_pdf_data[i,:,:]
            regieme_count[7] = regieme_count[7] + 1.0
        else:
            for reg in range(0,7):
                dists[reg] = np.linalg.norm(features - REG_CHARS.get(reg))
            regieme[i] = np.argmin(dists)
            regieme_pdf[int(regieme[i]), :, :] = joint_pdf_data[i,:,:]
            regieme_count[int(regieme[i])]=regieme_count[int(regieme[i])] + 1.0
            min_dists[i] = dists[np.argmin(dists)]
            if i==0 or i==10 or i==20 or i==30 or i==40 or i==50 or i==170:
                print(i,REGIEME_NAMES_TR.get(regieme[i]),dists,features)

    for reg in range(0,8):
        print(reg,np.sum(np.where(regieme==reg, 1.0, 0.0))*100./275.,regieme_count[reg]*100./275.)

    # create average regieme for each type and plot
    for reg in range(0,8):
        regieme_pdf[reg,:,:] = regieme_pdf[reg,:,:] / regieme_count[reg]
    
    fig = plt.figure(figsize=[11.4,11.4])
   
    for i in range(0,8):
        ax = plt.subplot(3,3,i+1)
        cs = ax.pcolormesh(regieme_pdf[i, :, :])
        plt.xticks([1,2,3,4,5,6,7], tauall, size=7, rotation=90)
        plt.yticks([1,2,3,4,5,6,7], ctpall, size=7)
        plt.title(REGIEME_NAMES_TR.get(i)+np.str(regieme_count[i]))
        plt.colorbar(cs)
    plt.savefig('williams_webb_tropical_clusters.eps')
    
    
########################################################
# main program

REGIONNAMES = {"TWP" : "Tropical_Western_Pacific"}

# latlons format[Latmin, latmax, lonmin, lonmax]
FILENAME = '/nfs/hera1/earjcti/ISCCP/clisccp_CFday_IPSL-CM6A-LR_midPliocene-eoi400_r1i1p1f1_gr_20250101-20491231.nc'

REGION='TWP' # TWP Tropical Western Pacific

regionpdfcubes = get_pdfcubes_region(0,366)
